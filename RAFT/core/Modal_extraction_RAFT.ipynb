{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from raft import RAFT  # Ensure RAFT is installed\n",
    "from utils.utils import InputPadder  # Helper from RAFT's utilities\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_and_extract_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read the first three lines\n",
    "        height = int(file.readline().strip())\n",
    "        width = int(file.readline().strip())\n",
    "        num_points = int(file.readline().strip())\n",
    "        \n",
    "        # Read the specified number of points\n",
    "        data = []\n",
    "        for _ in range(num_points):\n",
    "            line = file.readline().strip()\n",
    "            x, y = map(int, line.split(','))\n",
    "            data.append((x, y))\n",
    "\n",
    "    return height, width, num_points, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../Lukas Kanade + Simulation/tmp/goodflower-fp.txt'\n",
    "height, width, num_points, data_points = read_file_and_extract_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points=np.asarray(data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained RAFT model\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = Namespace(\n",
    "    small=True,\n",
    "    mixed_precision=True,\n",
    "    alternate_corr=False\n",
    ")\n",
    "raft_model = RAFT(args)\n",
    "# Load the state_dict\n",
    "state_dict = torch.load(\"../raft-kitti.pth\",map_location=torch.device('cpu'))\n",
    "\n",
    "# Remove 'module.' prefix from keys\n",
    "new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "# Load the modified state_dict into the model\n",
    "raft_model.to(DEVICE)\n",
    "raft_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "def calculate_optical_flow(prev_frame, next_frame, model):\n",
    "    with torch.no_grad():\n",
    "        # Prepare input\n",
    "        prev_tensor = torch.from_numpy(prev_frame).permute(2, 0, 1).float().unsqueeze(0).to(DEVICE) / 255.0\n",
    "        next_tensor = torch.from_numpy(next_frame).permute(2, 0, 1).float().unsqueeze(0).to(DEVICE) / 255.0\n",
    "        padder = InputPadder(prev_tensor.shape)\n",
    "        prev_tensor, next_tensor = padder.pad(prev_tensor, next_tensor)\n",
    "\n",
    "        # Compute flow\n",
    "        flow_low, flow_up = model(prev_tensor, next_tensor, iters=20, test_mode=True)\n",
    "        return padder.unpad(flow_up[0].cpu().numpy())\n",
    "    \n",
    "    \n",
    "# Helper function for RAFT optical flow\n",
    "def compute_fft_components(optical_flow, fps, max_frequency=30, num_points=212):\n",
    "    \"\"\"\n",
    "    Computes FFT components (real, imaginary) and magnitudes for optical flow up to a specified frequency.\n",
    "    \n",
    "    Args:\n",
    "    - optical_flow: A 2D array with shape (H, W, 2), containing flow values for x and y directions.\n",
    "    - fps: Frames per second of the input video.\n",
    "    - max_frequency: Maximum frequency (Hz) to include in the FFT results.\n",
    "    - num_points: Number of FFT points (limited to 451).\n",
    "    \n",
    "    Returns:\n",
    "    - fft_dx_real, fft_dx_imag, fft_dy_real, fft_dy_imag: FFT components limited to max_frequency.\n",
    "    - x_magnitudes, y_magnitudes: Magnitudes for dx and dy FFTs.\n",
    "    - valid_frequencies: Frequencies up to max_frequency.\n",
    "\n",
    "\"\"\"\n",
    "    n_bins=int(num_points/2)\n",
    "    h=optical_flow.shape[2]\n",
    "    w=optical_flow.shape[3]\n",
    "    fft_u = np.zeros((n_bins, h, w), dtype=complex)\n",
    "    fft_v = np.zeros((n_bins, h, w), dtype=complex)\n",
    "\n",
    "\n",
    "    for row in range(h):\n",
    "        for col in range(w):\n",
    "            pixel_fft_u = np.fft.fft(optical_flow[0, :, row, col], axis=0)\n",
    "            pixel_fft_v = np.fft.fft(optical_flow[1, :, row, col], axis=0)\n",
    "\n",
    "            fft_u[:, row, col] = pixel_fft_u[:n_bins]\n",
    "            fft_v[:, row, col] = pixel_fft_v[:n_bins]\n",
    "\n",
    "    # Compute frequency bins\n",
    "    frequencies = np.fft.rfftfreq(num_points)*60\n",
    "    frequencies = frequencies[:-1]\n",
    "\n",
    "\n",
    "    return fft_u, fft_v, frequencies\n",
    "\n",
    "def process_video_and_create_file(video_path, fps, max_frequency=30, num_points=212):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, prev_frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to read video.\")\n",
    "        return\n",
    "\n",
    "    optical_flow = np.zeros((2, num_points,prev_frame.shape[0] ,prev_frame.shape[1] ))\n",
    "\n",
    "    i=0\n",
    "\n",
    "    while True:\n",
    "        ret, next_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        \n",
    "        # Calculate optical flow using RAFT\n",
    "        optical_flow[:,i,:,:]= calculate_optical_flow(prev_frame, next_frame, raft_model)\n",
    "        i=+1\n",
    "        prev_frame = next_frame\n",
    "    # Compute FFT components (up to max_frequency)\n",
    "    fft_u,fft_v, frequencies = compute_fft_components(optical_flow, fps, max_frequency, num_points)\n",
    "\n",
    "\n",
    "    return fft_u, fft_v, frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_u, fft_v, frequencies=process_video_and_create_file(\"../../Lukas Kanade + Simulation/tmp/goodflower.mp4\",30)\n",
    "fft_u, fft_v, frequencies=process_video_and_create_file(\"../../Lukas Kanade + Simulation/tmp/goodflower.mp4\",30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fft_python(fft_dx_real, fft_dx_imag, fft_dy_real, fft_dy_imag, freqs):\n",
    "    # Remove the last frequency and corresponding data\n",
    "    freqs = freqs[:-1]\n",
    "    # fft_dx_real = fft_dx_real[:-1]\n",
    "    # fft_dx_imag = fft_dx_imag[:-1]\n",
    "    # fft_dy_real = fft_dy_real[:-1]\n",
    "    # fft_dy_imag = fft_dy_imag[:-1]\n",
    "\n",
    "    # Create output file\n",
    "    output_name = f\"goodflower-fft.txt\"\n",
    "    \n",
    "    with open(output_name, \"w\") as fs:\n",
    "        n_freqs = len(freqs)\n",
    "        n_features = fft_dx_real.shape[1]\n",
    "        \n",
    "        # Write number of frequencies and features\n",
    "        fs.write(f\"{n_freqs}\\n\")\n",
    "        fs.write(f\"{n_features}\\n\")\n",
    "        \n",
    "        # Calculate magnitudes and write them along with frequencies\n",
    "        for i in range(n_freqs):\n",
    "            x_mags = np.sqrt(fft_dx_real[i]**2 + fft_dx_imag[i]**2)\n",
    "            y_mags = np.sqrt(fft_dy_real[i]**2 + fft_dy_imag[i]**2)\n",
    "            x_mag_sum = np.sum(x_mags)\n",
    "            y_mag_sum = np.sum(y_mags)\n",
    "            fs.write(f\"{freqs[i]},{x_mag_sum},{y_mag_sum}\\n\")\n",
    "        \n",
    "        # Helper function to write matrix data\n",
    "        def write_cv_mat(mat):\n",
    "            for row in mat:\n",
    "                fs.write(\",\".join(map(str, row)) + \"\\n\")\n",
    "        \n",
    "        # Write matrix data\n",
    "        write_cv_mat(fft_dx_real)\n",
    "        write_cv_mat(fft_dx_imag)\n",
    "        write_cv_mat(fft_dy_real)\n",
    "        write_cv_mat(fft_dy_imag)\n",
    "\n",
    "    print(f\"File saved as {output_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as goodflower-fft.txt\n"
     ]
    }
   ],
   "source": [
    "save_fft_python(np.real(fft_u[:,data_points[:,1],data_points[:,0]]), np.imag(fft_u[:,data_points[:,1],data_points[:,0]]), np.real(fft_v[:,data_points[:,1],data_points[:,0]]), np.imag(fft_v[:,data_points[:,1],data_points[:,0]]), frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
